version: "3.8"

services:
  # === Download Stack ===
  gluetun:
    image: qmcgaw/gluetun:latest
    container_name: vpn
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun:/dev/net/tun
    ports:
      - "${QBIT_PORT:-8080}:8080"
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
      - VPN_SERVICE_PROVIDER=nordvpn
      - VPN_TYPE=wireguard
      - WIREGUARD_PRIVATE_KEY=${WIREGUARD_PRIVATE_KEY}
      - SERVER_COUNTRIES=${SERVER_COUNTRIES}
      - FIREWALL=on
      - FIREWALL_OUTBOUND_SUBNETS=172.16.0.0/12,192.168.0.0/16 
      - DOT=off
      - LOG_LEVEL=info
      - UPDATER_PERIOD=24h
      - HEALTH_TARGET_ADDRESS=1.1.1.1:443
      - HEALTH_READ_TIMEOUT=2s
      - HEALTH_WAIT_DURATION=10s
    volumes:
      - ${CONFIG_DIR:-./config}/gluetun:/gluetun
    networks:
      - media_net
    restart: unless-stopped
    mem_limit: 256M
    memswap_limit: 512M
    #healthcheck:
      #test: ["CMD", "sh", "-c", "wget -q --spider http://127.0.0.1:9999/healthcheck"]
      #interval: 30s
      #timeout: 15s
      #retries: 3
      #start_period: 60s
    labels:
      - flame.type=app
      - flame.name=Gluetun VPN
      - flame.url=http://${HOST_IP}:${QBIT_PORT:-8080}
      - flame.icon=vpn
      - homepage.group=VPN & Downloads
      - homepage.name=Gluetun VPN
      - homepage.icon=vpn
      - homepage.hrefhttp://${HOST_IP}:${QBIT_PORT:-8080}
      - homepage.description=NordVPN WireGuard container
 
  qbittorrent:
    image: linuxserver/qbittorrent:latest
    container_name: qbittorrent
    network_mode: "service:gluetun"
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
      - WEBUI_PORT=${QBIT_PORT:-8080}
    volumes:
      - ${BASE_PATH}/qbittorrent:/config
      - ${DOWNLOAD_DIR}:/downloads:cached
      - ${INCOMPLETE_DOWNLOAD_DIR}:/incomplete:cached
    restart: unless-stopped
    mem_limit: 1024M
    memswap_limit: 1536M
    healthcheck:
      test: ["CMD", "sh", "-c", "wget -q --spider http://localhost:8080"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s
    labels:
      - flame.type=app
      - flame.name=qBittorrent
      - flame.url=http://${HOST_IP}:${QBIT_PORT:-8080}
      - flame.icon=download
      - homepage.group=VPN & Downloads
      - homepage.name=qBittorrent
      - homepage.icon=qbittorrent
      - homepage.href=http://${HOST_IP}:${QBIT_PORT:-8080}
      - homepage.description=Torrent client via VPN
      - homepage.widget.type=qbittorrent
      - homepage.widget.url=http://${HOST_IP}:${QBIT_PORT:-8080}
      - homepage.widget.username=admin
      - homepage.widget.password=squonk

  # === Media Management ===
  prowlarr:
    image: linuxserver/prowlarr:latest
    container_name: prowlarr
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
    volumes:
      - ${BASE_PATH}/prowlarr:/config
    ports:
      - "${PROWLARR_PORT:-9696}:9696"
    networks:
      - media_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--fail", "--silent", "--show-error", "http://localhost:9696/prowlarr/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=Prowlarr
      - flame.url=http://${HOST_IP}:${PROWLARR_PORT:-9696}
      - flame.icon=plus-network-outline
      - homepage.group=Media Management
      - homepage.name=Prowlarr
      - homepage.icon=prowlarr
      - homepage.href=http://${HOST_IP}:${PROWLARR_PORT:-9696}
      - homepage.description=Indexer manager
      - homepage.widget.type=prowlarr
      - homepage.widget.url=http://prowlarr:9696
      - homepage.widget.key=${PROWLARR_KEY}

  sonarr:
    image: linuxserver/sonarr:latest
    container_name: sonarr
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
    volumes:
      - ${BASE_PATH}/sonarr:/config
      - ${MEDIA_SHARE}:/media:cached
      - ${DOWNLOAD_DIR}:/downloads:cached
    ports:
      - "${SONARR_PORT:-8989}:8989"
    networks:
      - media_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--fail", "--silent", "--show-error", "http://localhost:8989/sonarr/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=Sonarr
      - flame.url=http://${HOST_IP}:${SONARR_PORT:-8989}
      - flame.icon=television-classic
      - homepage.group=Media Management
      - homepage.name=Sonarr
      - homepage.icon=sonarr
      - homepage.href=http://${HOST_IP}:${SONARR_PORT:-8989}
      - homepage.description=TV show management
      - homepage.widget.type=sonarr
      - homepage.widget.url=http://sonarr:8989
      - homepage.widget.key=${SONARR_KEY}

  radarr:
    image: linuxserver/radarr:latest
    container_name: radarr
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
    volumes:
      - ${BASE_PATH}/radarr:/config
      - ${MEDIA_SHARE}:/media:cached
      - ${DOWNLOAD_DIR}:/downloads:cached
    ports:
      - "${RADARR_PORT:-7878}:7878"
    networks:
      - media_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--fail", "--silent", "--show-error", "http://localhost:7878/radarr/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=Radarr
      - flame.url=http://${HOST_IP}:${RADARR_PORT:-7878}
      - flame.icon=video-vintage
      - homepage.group=Media Management
      - homepage.name=Radarr
      - homepage.icon=radarr
      - homepage.href=http://${HOST_IP}:${RADARR_PORT:-7878}
      - homepage.description=Movie management
      - homepage.widget.type=radarr
      - homepage.widget.url=http://radarr:7878
      - homepage.widget.key=${RADARR_KEY}

  bazarr:
    container_name: bazarr
    image: linuxserver/bazarr:latest
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
    volumes:
      - ${BASE_PATH}/bazarr:/config
      - ${MEDIA_SHARE}:/media:cached
    ports:
      - "${BAZARR_PORT:-6767}:6767"
    networks:
      - media_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "--silent", "--show-error", "http://localhost:6767/bazarr/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=Bazarr
      - flame.url=http://${HOST_IP}:${BAZARR_PORT:-6767}
      - flame.icon=subtitles-outline
      - homepage.group=Media Management
      - homepage.name=Bazarr
      - homepage.icon=bazarr
      - homepage.href=http://${HOST_IP}:${BAZARR_PORT:-6767}
      - homepage.description=Subtitle management
      - homepage.widget.type=bazarr
      - homepage.widget.url=http://bazarr:6767
      - homepage.widget.key=${BAZARR_KEY}

  cleanuparr:
    image: ghcr.io/cleanuparr/cleanuparr:latest
    container_name: cleanuparr
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
      - PORT=11011
      - BASE_PATH=
      - UMASK=022
    volumes:
      - ${BASE_PATH}/cleanuparr:/config
      - ${DOWNLOAD_DIR}:/downloads:cached
      - ${MEDIA_SHARE}:/media:cached
    ports:
      - "${CLEANUPARR_PORT:-11011}:11011"
    networks:
      - media_net
    restart: unless-stopped
    deploy:                                         # Resource limits
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    logging:                                        # Limit logging
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11011/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=Cleanuparr
      - flame.url=http://${HOST_IP}:${CLEANUPARR_PORT:-11011}
      - flame.icon=broom
      - homepage.group=Maintenance & Tools
      - homepage.name=Cleanuparr
      - homepage.icon=cleanuparr
      - homepage.href=http://${HOST_IP}:${CLEANUPARR_PORT:-11011}
      - homepage.description=Download cleanup automation
      - homepage.widget.type=cleanuparr
      - homepage.widget.url=http://cleanuparr:${CLEANUPARR_PORT:-11011}
      - homepage.widget.key=${CLEANUPARR_KEY:-}

  huntarr:
    image: ghcr.io/plexguide/huntarr:latest
    container_name: huntarr
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
    volumes:
      - ${BASE_PATH}/huntarr:/config
    ports:
      - "${HUNTARR_PORT:-9705}:9705"
    networks:
      - media_net
    restart: unless-stopped
    deploy:                                         # Resource limits
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    logging:                                        # Limit logging
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
    healthcheck:
      test: ["CMD", "sh", "-c", "netstat -ltn | grep -c ':9705' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=Huntarr
      - flame.url=http://${HOST_IP}:${HUNTARR_PORT:-9705}
      - flame.icon=magnify
      - homepage.group=Media Management
      - homepage.name=Huntarr
      - homepage.icon=huntarr
      - homepage.href=http://${HOST_IP}:${HUNTARR_PORT:-9705}
      - homepage.description=Missing content hunter
      - homepage.widget.type=huntarr
      - homepage.widget.url=http://huntarr:${HUNTARR_PORT:-9705}
      - homepage.widget.key=${HUNTARR_KEY:-}

  # === Media Servers ===
  plex:
    image: linuxserver/plex:latest
    container_name: plex
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    network_mode: host
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
      - VERSION=docker
      - PLEX_CLAIM=${PLEX_CLAIM}
      - NVIDIA_DRIVER_CAPABILITIES=all
      - NVIDIA_VISIBLE_DEVICES=all
      - PLEX_DEBUG=1
      - PLEX_MEDIA_SERVER_USE_SYSLOG=true
    volumes:
      - ${FAST_MOUNT}/plex/config:/config           
      - ${FAST_MOUNT}/plex/transcode:/transcode
      - ${MEDIA_SHARE}/tv:/tv:cached
      - ${MEDIA_SHARE}/movies:/movies:cached
      - ${MEDIA_SHARE}/system:/system:ro,cached
    devices:
      - /dev/dri:/dev/dri
    restart: unless-stopped
    logging:                                        # NEW: Limit logging
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
    healthcheck:
      test: ["CMD", "curl", "-f", "--silent", "--show-error", "http://localhost:32400/identity"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    privileged: true
    labels:
      - flame.type=app
      - flame.name=Plex
      - flame.url=http://${HOST_IP}:32400/web
      - flame.icon=plex
      - homepage.group=Media Servers
      - homepage.name=Plex Media Server
      - homepage.icon=plex
      - homepage.href=http://${HOST_IP}:32400/web
      - homepage.description=Media streaming server
      - homepage.widget.type=plex
      - homepage.widget.url=http://${HOST_IP}:32400
      - homepage.widget.key=${PLEX_TOKEN}

  wizarr:
    image: ghcr.io/wizarrrr/wizarr:latest
    container_name: wizarr
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
    volumes:
      - ${BASE_PATH}/wizarr/database:/data/database  
    ports:
      - "${WIZARR_PORT:-5690}:5690"
    networks:
      - media_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "--silent", "--show-error", "http://localhost:5690/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=Wizarr
      - flame.url=http://${HOST_IP}:${WIZARR_PORT:-5690}
      - flame.icon=account-plus
      - homepage.group=Request Management
      - homepage.name=Wizarr
      - homepage.icon=wizarr
      - homepage.href=http://${HOST_IP}:${WIZARR_PORT:-5690}
      - homepage.description=User invitation system


  tautulli:
    image: ghcr.io/tautulli/tautulli:latest
    container_name: tautulli
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
    volumes:
      - ${BASE_PATH}/tautulli:/config
    ports:
      - "${TAUTULLI_PORT:-8181}:8181"
    networks:
      - media_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "--silent", "--show-error", "http://localhost:8181/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=Tautulli
      - flame.url=http://${HOST_IP}:${TAUTULLI_PORT:-8181}
      - flame.icon=chart-line
      - homepage.group=Statistics & Monitoring
      - homepage.name=Tautulli
      - homepage.icon=tautulli
      - homepage.href=http://${HOST_IP}:${TAUTULLI_PORT:-8181}
      - homepage.description=Plex analytics
      - homepage.widget.type=tautulli
      - homepage.widget.url=http://tautulli:8181
      - homepage.widget.key=${TAUTULLI_KEY}
      
  jellyfin:
    image: jellyfin/jellyfin:latest
    container_name: jellyfin
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
      - JELLYFIN_CONFIG_DIR=/config/config
      - JELLYFIN_DATA_DIR=/config
      - JELLYFIN_CACHE_DIR=/cache
      - JELLYFIN_LOG_DIR=/config/log
    volumes:
      - ${BASE_PATH}/jellyfin/config:/config
      - ${FAST_MOUNT}/jellyfin/cache:/cache         # CHANGED: Cache on NVMe
      - ${MEDIA_SHARE}/tv:/tv:ro,cached
      - ${MEDIA_SHARE}/movies:/movies:ro,cached
      - ${MEDIA_SHARE}/music:/music:ro,cached
      - ${MEDIA_SHARE}/system:/system:ro,cached
    ports:
      - "${JELLYFIN_PORT:-8096}:8096"
      - "7359:7359/udp"
      - "1900:1900/udp"
    networks:
      - media_net
    restart: unless-stopped
    logging:                                        # NEW: Limit logging
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
    healthcheck:
      test: ["CMD", "curl", "-f", "--silent", "--show-error", "http://localhost:8096/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    labels:
      - flame.type=app
      - flame.name=Jellyfin
      - flame.url=http://${HOST_IP}:${JELLYFIN_PORT:-8096}
      - flame.icon=jellyfish-outline

  # === Optional Services ===
  watchtower:
    image: containrrr/watchtower:latest
    container_name: watchtower
    environment:
      - TZ=${TZ}
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_INCLUDE_STOPPED=false
      - WATCHTOWER_SCHEDULE=${WATCHTOWER_SCHEDULE:-0 3 0 * * 6} 
      - WATCHTOWER_NOTIFICATION_REPORT=true
      - WATCHTOWER_NOTIFICATIONS=shoutrrr
      - WATCHTOWER_NOTIFICATION_URL=${WATCHTOWER_NOTIFICATION_URL:-}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /etc/localtime:/etc/localtime:ro
    ports:
      - "${WATCHTOWER_PORT:-8081}:8080"
    networks:
      - media_net
    restart: unless-stopped
    labels:
      - flame.type=app
      - flame.name=Watchtower
      - flame.url=http://${HOST_IP}:${WATCHTOWER_PORT:-8081}
      - flame.icon=update

      
  flaresolverr:
    image: ghcr.io/flaresolverr/flaresolverr:latest
    container_name: flaresolverr
    environment:
      - LOG_LEVEL=info
      - LOG_HTML=false
      - CAPTCHA_SOLVER=none
      - TZ=${TZ}
    ports:
      - "${FLARESOLVERR_PORT:-8191}:8191"
    networks:
      - media_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "--silent", "--show-error", "http://localhost:8191/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=FlareSolverr
      - flame.url=http://${HOST_IP}:${FLARESOLVERR_PORT:-8191}
      - flame.icon=puzzle

  overseerr:
    image: lscr.io/linuxserver/overseerr:latest
    container_name: overseerr
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
    volumes:
      - ${BASE_PATH}/overseerr:/config
    ports:
      - "${OVERSEERR_PORT:-5055}:5055"
    networks:
      - media_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "--silent", "--show-error", "http://localhost:5055/api/v1/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - flame.type=app
      - flame.name=Overseerr
      - flame.url=http://${HOST_IP}:${OVERSEERR_PORT:-5055}
      - flame.icon=format-list-bulleted-triangle
      - homepage.group=Request Management
      - homepage.name=Overseerr
      - homepage.icon=overseerr
      - homepage.href=http://${HOST_IP}:${OVERSEERR_PORT:-5055}
      - homepage.description=Media request management
      - homepage.widget.type=overseerr
      - homepage.widget.url=http://overseerr:5055
      - homepage.widget.key=${OVERSEER_KEY}

  maintainerr:
    image: ghcr.io/jorenn92/maintainerr:latest
    container_name: maintainerr
    user: ${PUID}:${PGID}
    environment:
      - TZ=${TZ}
      - UI_PORT=${MAINTAINERR_PORT:-6246}
      - API_PORT=${MAINTAINERR_API_PORT:-3001}
    volumes:
      - ${BASE_PATH}/maintainerr:/opt/data:rw
    ports:
      - "${MAINTAINERR_PORT:-6246}:6246"
    networks:
      - media_net
    restart: unless-stopped
    deploy:                                         # NEW: Resource limits
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    logging:                                        # NEW: Limit logging
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    #healthcheck:
      #test: ["CMD", "wget", "-qO-", "http://localhost:${MAINTAINERR_PORT:-6246}/health"]
      #interval: 30s
      #timeout: 10s
      #retries: 3
      #start_period: 10s
    labels:
      - flame.type=app
      - flame.name=Maintainerr
      - flame.url=http://${HOST_IP}:${MAINTAINERR_PORT:-6246}
      - flame.icon=trash-can-outline
      - homepage.group=Maintenance & Tools
      - homepage.name=Maintainerr
      - homepage.icon=maintainerr
      - homepage.href=http://192.168.31.101:6246
      - homepage.description=Media library maintenance

  flame:
    image: pawelmalak/flame:latest
    container_name: flame
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
      - PASSWORD=${FLAME_PASSWORD:-flame}
    volumes:
      - ${BASE_PATH}/flame:/app/data
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "${FLAME_PORT:-1313}:5005"
    networks:
      - media_net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5005"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - flame.type=app
      - flame.name=Flame
      - flame.url=http://${HOST_IP}:${FLAME_PORT:-5005}
      - flame.icon=fire
      - homepage.group=Dashboards
      - homepage.name=Flame (Legacy)
      - homepage.icon=flame
      - homepage.href=http://192.168.31.101:1313
      - homepage.description=Previous dashboard

  homepage:
    image: ghcr.io/gethomepage/homepage:latest
    container_name: homepage
    environment:
      - PUID=1000          # Keep same user ID
      - PGID=999           # Use docker group ID specifically for Homepage
      - HOMEPAGE_ALLOWED_HOSTS=*
    ports:
      - "3000:3000"
    volumes:
      - ${BASE_PATH}/homepage:/app/config
      - /var/run/docker.sock:/var/run/docker.sock:ro
    restart: unless-stopped
    networks:
      - media_net

  autoheal:
    image: willfarrell/autoheal:latest
    container_name: autoheal
    restart: always
    environment:
      - AUTOHEAL_CONTAINER_LABEL=all
      - AUTOHEAL_INTERVAL=30
      - AUTOHEAL_START_PERIOD=300
      - AUTOHEAL_DEFAULT_STOP_TIMEOUT=30
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - media_net

# === Transcoding Services ===
  fileflows:
    image: revenz/fileflows:stable
    container_name: fileflows
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
      - TempPathHost=${FAST_MOUNT}/fileflows/temp   # CHANGED: Use NVMe for temp files
    volumes:
      - ${BASE_PATH}/fileflows:/app/Data
      - ${FAST_MOUNT}/fileflows/temp:/temp          # CHANGED: NVMe temp processing
      - ${FAST_MOUNT}/fileflows/logs:/app/Logs      # CHANGED: NVMe logs
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ${MEDIA_SHARE}:/library:cached
    ports:
      - "${FILEFLOWS_PORT:-19200}:5000"
    networks:
      - media_net
    restart: unless-stopped
    devices:
      - /dev/dri:/dev/dri
    logging:                                        # NEW: Limit logging
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    labels:
      - flame.type=app
      - flame.name=FileFlows
      - flame.url=http://${HOST_IP}:${FILEFLOWS_PORT:-19200}
      - flame.icon=transfer
      - homepage.group=Maintenance & Tools
      - homepage.name=FileFlows
      - homepage.icon=fileflows
      - homepage.href=http://192.168.31.101:19200
      - homepage.description=File processing automation

networks:
  media_net:
    driver: bridge
